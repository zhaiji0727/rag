{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def weighted_mean_pooling(hidden, attention_mask):\n",
    "    attention_mask_ = attention_mask * attention_mask.cumsum(dim=1)\n",
    "    s = torch.sum(hidden * attention_mask_.unsqueeze(-1).float(), dim=1)\n",
    "    d = attention_mask_.sum(dim=1, keepdim=True).float()\n",
    "    reps = s / d\n",
    "    return reps\n",
    "\n",
    "\n",
    "def encode(text_or_image_list):\n",
    "    \n",
    "    if (isinstance(text_or_image_list[0], str)):\n",
    "        inputs = {\n",
    "            \"text\": text_or_image_list,\n",
    "            'image': [None] * len(text_or_image_list),\n",
    "            'tokenizer': tokenizer\n",
    "        }\n",
    "    else:\n",
    "        inputs = {\n",
    "            \"text\": [''] * len(text_or_image_list),\n",
    "            'image': text_or_image_list,\n",
    "            'tokenizer': tokenizer\n",
    "        }\n",
    "    outputs = model(**inputs)\n",
    "    attention_mask = outputs.attention_mask\n",
    "    hidden = outputs.last_hidden_state\n",
    "\n",
    "    reps = weighted_mean_pooling(hidden, attention_mask)   \n",
    "    embeddings = F.normalize(reps, p=2, dim=1).detach().cpu().numpy()\n",
    "    return embeddings\n",
    "model_name_or_path = \"./VisRAG-Ret\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16, trust_remote_code=True).cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "ArxivQA_corpus_ds = load_dataset(\"dataset/VisRAG-Ret-Test-ArxivQA\", name=\"corpus\", split=\"train\")\n",
    "image_embeddings = []\n",
    "i = 0\n",
    "for item in tqdm(ArxivQA_corpus_ds):\n",
    "    image_id = item['corpus-id']\n",
    "    image = item['image']\n",
    "    width, height = image.size\n",
    "    # print(width, height)\n",
    "    crop_width = width // 2\n",
    "    crop_height = height // 2\n",
    "    cropped_images = [\n",
    "        image.crop((0, 0, crop_width, crop_height)).convert('RGB'),\n",
    "        image.crop((crop_width, 0, width, crop_height)).convert('RGB'),\n",
    "        image.crop((0, crop_height, crop_width, height)).convert('RGB'),\n",
    "        image.crop((crop_width, crop_height, width, height)).convert('RGB')\n",
    "    ]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(cropped_images[i])\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # embedding = encode(cropped_images)\n",
    "    # # embedding2 = [encode([img]) for img in cropped_images]\n",
    "    # # print(embedding)\n",
    "    # image_embeddings.append(embedding)\n",
    "    \n",
    "    \n",
    "image_embeddings = np.array(image_embeddings)\n",
    "    \n",
    "np.save(f\"embeddings/PlotQA_corpus_embeddings_4x4.npy\", image_embeddings)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9593, 16, 2304)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "saved_embeddings = np.load('embeddings/SlideVQA_corpus_embeddings_4x4.npy')\n",
    "saved_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/ArxivQA_corpus_embeddings_4x4_0.2.npy')\n",
    "image_embeddings = np.load('embeddings/ArxivQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/ArxivQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/ArxivQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/ArxivQA_queries_query_ids.npy')\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-PlotQA/qrels/plotqa-eval-qrels.tsv')\n",
    "\n",
    "# alpha = []\n",
    "\n",
    "# for i in image_embeddings.shape[0]:\n",
    "#     for j in image_embeddings.shape[1]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mrr(qrel, run, cutoff=None):  \n",
    "    \"\"\"  \n",
    "    Compute MRR@cutoff manually.  \n",
    "    \"\"\"  \n",
    "    mrr = 0.0  \n",
    "    num_ranked_q = 0  \n",
    "    results = {}  \n",
    "    for qid in qrel:  \n",
    "        if qid not in run:  \n",
    "            continue  \n",
    "        num_ranked_q += 1  \n",
    "        docid_and_score = [(docid, score) for docid, score in run[qid].items()]  \n",
    "        docid_and_score.sort(key=lambda x: x[1], reverse=True)  \n",
    "        for i, (docid, _) in enumerate(docid_and_score):  \n",
    "            rr = 0.0  \n",
    "            if cutoff is None or i < cutoff:  \n",
    "                if docid in qrel[qid] and qrel[qid][docid] > 0:  \n",
    "                    rr = 1.0 / (i + 1)  \n",
    "                    break  \n",
    "        results[qid] = rr  \n",
    "        mrr += rr  \n",
    "    mrr /= num_ranked_q  \n",
    "    results[\"all\"] = mrr  \n",
    "    return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4269\n",
      "recall_10                all     0.5912\n",
      "MRR@10: 0.3756275435500701\n"
     ]
    }
   ],
   "source": [
    "import pytrec_eval\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {\"ndcg_cut.10\", \"recall.10\"})  \n",
    "eval_results = evaluator.evaluate(run)  \n",
    "  \n",
    "for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "    value = pytrec_eval.compute_aggregated_measure(  \n",
    "        measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "    )  \n",
    "    print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "  \n",
    "mrr_at_10 = eval_mrr(qrels, run, 10)['all']  \n",
    "print(f'MRR@10: {mrr_at_10}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4521\n",
      "recall_10                all     0.6149\n",
      "MRR@10: 0.40120304039778676\n",
      "gamma: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4522\n",
      "recall_10                all     0.6148\n",
      "MRR@10: 0.401392205418472\n",
      "gamma: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4523\n",
      "recall_10                all     0.6145\n",
      "MRR@10: 0.4015224450087805\n",
      "gamma: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4522\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.4015948471307979\n",
      "gamma: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4522\n",
      "recall_10                all     0.6132\n",
      "MRR@10: 0.4017886447642349\n",
      "gamma: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4525\n",
      "recall_10                all     0.6136\n",
      "MRR@10: 0.40209460777913936\n",
      "gamma: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4526\n",
      "recall_10                all     0.6134\n",
      "MRR@10: 0.40217139684505004\n",
      "gamma: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4525\n",
      "recall_10                all     0.6134\n",
      "MRR@10: 0.40214075842889857\n",
      "gamma: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4527\n",
      "recall_10                all     0.6135\n",
      "MRR@10: 0.4022689624772404\n",
      "gamma: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4527\n",
      "recall_10                all     0.6138\n",
      "MRR@10: 0.40226703222192767\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4525\n",
      "recall_10                all     0.6137\n",
      "MRR@10: 0.40208435987820473\n",
      "gamma: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 199.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4528\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.4023343805845798\n",
      "gamma: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4526\n",
      "recall_10                all     0.6138\n",
      "MRR@10: 0.4021318090633558\n",
      "gamma: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4529\n",
      "recall_10                all     0.6144\n",
      "MRR@10: 0.40232634370336684\n",
      "gamma: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4529\n",
      "recall_10                all     0.6148\n",
      "MRR@10: 0.4022827199332904\n",
      "gamma: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4528\n",
      "recall_10                all     0.6147\n",
      "MRR@10: 0.4021365118672095\n",
      "gamma: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4528\n",
      "recall_10                all     0.6145\n",
      "MRR@10: 0.40227429700101464\n",
      "gamma: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 199.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4529\n",
      "recall_10                all     0.6145\n",
      "MRR@10: 0.4024000443607763\n",
      "gamma: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 199.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4527\n",
      "recall_10                all     0.6143\n",
      "MRR@10: 0.4021201924359258\n",
      "gamma: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4527\n",
      "recall_10                all     0.6143\n",
      "MRR@10: 0.4021347921852028\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4524\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.40187680478871707\n"
     ]
    }
   ],
   "source": [
    "# 探索实验 针对gamma进行调参\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "\n",
    "# gamma_list = [round(0.1 * i, 1) for i in range(11)]\n",
    "gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "\n",
    "results = {}\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {\"ndcg_cut.10\", \"recall.10\"})  \n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        scores_exp = torch.exp(scores)\n",
    "        scores_sum = torch.sum(scores_exp, dim=1, keepdim=True)\n",
    "        alpha = scores_exp / (scores_sum + 1e-8)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "\n",
    "    eval_results = evaluator.evaluate(run)  \n",
    "    \n",
    "    for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "        value = pytrec_eval.compute_aggregated_measure(  \n",
    "            measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "        )  \n",
    "        print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "        # results[gamma][measure] = value\n",
    "    \n",
    "    mrr_at_10 = eval_mrr(qrels, run, 10)['all']  \n",
    "    print(f'MRR@10: {mrr_at_10}')  \n",
    "    \n",
    "    # results[gamma]['mrr_at_10'] =  mrr_at_10\n",
    "\n",
    "# import json\n",
    "# with open('PlotQA_gamma_tuning.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:57<00:00, 198.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.1823\n",
      "recall_10                all     0.3187\n",
      "MRR@10: 0.1406790076662717\n",
      "ndcg_cut_5               all     0.1514\n",
      "recall_5                 all     0.2229\n",
      "MRR@5: 0.12797529553963652\n",
      "ndcg_cut_3               all     0.1271\n",
      "recall_3                 all     0.1638\n",
      "MRR@3: 0.1145455617464107\n",
      "ndcg_cut_1               all     0.0780\n",
      "recall_1                 all     0.0780\n",
      "MRR@1: 0.07800477580260017\n",
      "gamma: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:57<00:00, 197.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.2740\n",
      "recall_10                all     0.4396\n",
      "MRR@10: 0.2229289062401292\n",
      "ndcg_cut_5               all     0.2402\n",
      "recall_5                 all     0.3349\n",
      "MRR@5: 0.20896494796733556\n",
      "ndcg_cut_3               all     0.2112\n",
      "recall_3                 all     0.2642\n",
      "MRR@3: 0.1929041007045773\n",
      "ndcg_cut_1               all     0.1387\n",
      "recall_1                 all     0.1387\n",
      "MRR@1: 0.1386751569824003\n",
      "gamma: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 199.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3446\n",
      "recall_10                all     0.5155\n",
      "MRR@10: 0.2914593572460393\n",
      "ndcg_cut_5               all     0.3124\n",
      "recall_5                 all     0.4158\n",
      "MRR@5: 0.27819787152501446\n",
      "ndcg_cut_3               all     0.2818\n",
      "recall_3                 all     0.3412\n",
      "MRR@3: 0.2612393502550058\n",
      "ndcg_cut_1               all     0.1993\n",
      "recall_1                 all     0.1993\n",
      "MRR@1: 0.1993455381622004\n",
      "gamma: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 199.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3894\n",
      "recall_10                all     0.5589\n",
      "MRR@10: 0.336451257192836\n",
      "ndcg_cut_5               all     0.3584\n",
      "recall_5                 all     0.4635\n",
      "MRR@5: 0.32358273635800966\n",
      "ndcg_cut_3               all     0.3282\n",
      "recall_3                 all     0.3900\n",
      "MRR@3: 0.3068895374546769\n",
      "ndcg_cut_1               all     0.2430\n",
      "recall_1                 all     0.2430\n",
      "MRR@1: 0.24303528787476783\n",
      "gamma: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 199.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4169\n",
      "recall_10                all     0.5848\n",
      "MRR@10: 0.36448337242977896\n",
      "ndcg_cut_5               all     0.3867\n",
      "recall_5                 all     0.4920\n",
      "MRR@5: 0.3519147430795089\n",
      "ndcg_cut_3               all     0.3555\n",
      "recall_3                 all     0.4162\n",
      "MRR@3: 0.3346157247722678\n",
      "ndcg_cut_1               all     0.2712\n",
      "recall_1                 all     0.2712\n",
      "MRR@1: 0.27115945874237196\n",
      "gamma: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 201.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4331\n",
      "recall_10                all     0.5994\n",
      "MRR@10: 0.38107114429746514\n",
      "ndcg_cut_5               all     0.4032\n",
      "recall_5                 all     0.5077\n",
      "MRR@5: 0.3685696176409898\n",
      "ndcg_cut_3               all     0.3727\n",
      "recall_3                 all     0.4336\n",
      "MRR@3: 0.35169953715987456\n",
      "ndcg_cut_1               all     0.2880\n",
      "recall_1                 all     0.2880\n",
      "MRR@1: 0.287963208631821\n",
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:57<00:00, 198.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4425\n",
      "recall_10                all     0.6092\n",
      "MRR@10: 0.3903633231837004\n",
      "ndcg_cut_5               all     0.4128\n",
      "recall_5                 all     0.5180\n",
      "MRR@5: 0.3779929836974147\n",
      "ndcg_cut_3               all     0.3826\n",
      "recall_3                 all     0.4444\n",
      "MRR@3: 0.36125114236019346\n",
      "ndcg_cut_1               all     0.2971\n",
      "recall_1                 all     0.2971\n",
      "MRR@1: 0.2970726098876802\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:57<00:00, 198.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4479\n",
      "recall_10                all     0.6119\n",
      "MRR@10: 0.39651996024375963\n",
      "ndcg_cut_5               all     0.4195\n",
      "recall_5                 all     0.5249\n",
      "MRR@5: 0.38465404911411766\n",
      "ndcg_cut_3               all     0.3877\n",
      "recall_3                 all     0.4479\n",
      "MRR@3: 0.36701453376964444\n",
      "ndcg_cut_1               all     0.3048\n",
      "recall_1                 all     0.3048\n",
      "MRR@1: 0.30476695852127\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:57<00:00, 198.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4510\n",
      "recall_10                all     0.6137\n",
      "MRR@10: 0.4000495549182205\n",
      "ndcg_cut_5               all     0.4228\n",
      "recall_5                 all     0.5274\n",
      "MRR@5: 0.38829928362960936\n",
      "ndcg_cut_3               all     0.3906\n",
      "recall_3                 all     0.4491\n",
      "MRR@3: 0.3704342442734619\n",
      "ndcg_cut_1               all     0.3103\n",
      "recall_1                 all     0.3103\n",
      "MRR@1: 0.3102502874325639\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 198.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4525\n",
      "recall_10                all     0.6147\n",
      "MRR@10: 0.401748881504785\n",
      "ndcg_cut_5               all     0.4246\n",
      "recall_5                 all     0.5291\n",
      "MRR@5: 0.3901093717755954\n",
      "ndcg_cut_3               all     0.3924\n",
      "recall_3                 all     0.4507\n",
      "MRR@3: 0.3722620205772261\n",
      "ndcg_cut_1               all     0.3113\n",
      "recall_1                 all     0.3113\n",
      "MRR@1: 0.3113115768992659\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:56<00:00, 200.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4524\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.40187680478871707\n",
      "ndcg_cut_5               all     0.4237\n",
      "recall_5                 all     0.5262\n",
      "MRR@5: 0.38985289348780916\n",
      "ndcg_cut_3               all     0.3930\n",
      "recall_3                 all     0.4515\n",
      "MRR@3: 0.37283688570502327\n",
      "ndcg_cut_1               all     0.3122\n",
      "recall_1                 all     0.3122\n",
      "MRR@1: 0.31219598478818433\n"
     ]
    }
   ],
   "source": [
    "# 探索实验 针对gamma进行调参\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        alpha = torch.softmax(scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10, 5, 3, 1]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1: 1.0, gamma2: 0.0, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 145.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4524\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.40187680478871707\n",
      "gamma1: 0.9, gamma2: 0.1, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 146.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4518\n",
      "recall_10                all     0.6143\n",
      "MRR@10: 0.40101657773454097\n",
      "gamma1: 0.9, gamma2: 0.0, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 147.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4518\n",
      "recall_10                all     0.6142\n",
      "MRR@10: 0.40095624848211797\n",
      "gamma1: 0.8, gamma2: 0.2, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 146.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4467\n",
      "recall_10                all     0.6094\n",
      "MRR@10: 0.3958235241267886\n",
      "gamma1: 0.8, gamma2: 0.1, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 147.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4495\n",
      "recall_10                all     0.6121\n",
      "MRR@10: 0.39868405721417155\n",
      "gamma1: 0.8, gamma2: 0.0, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 146.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4472\n",
      "recall_10                all     0.6095\n",
      "MRR@10: 0.3964506465302445\n",
      "gamma1: 0.7, gamma2: 0.3, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 148.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4341\n",
      "recall_10                all     0.5973\n",
      "MRR@10: 0.38306025484985484\n",
      "gamma1: 0.7, gamma2: 0.2, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 148.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4403\n",
      "recall_10                all     0.6037\n",
      "MRR@10: 0.38916024769036195\n",
      "gamma1: 0.7, gamma2: 0.1, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 145.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4422\n",
      "recall_10                all     0.6050\n",
      "MRR@10: 0.3913182029393233\n",
      "gamma1: 0.7, gamma2: 0.0, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 147.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4383\n",
      "recall_10                all     0.5997\n",
      "MRR@10: 0.3878934737716918\n",
      "gamma1: 0.6, gamma2: 0.4, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 148.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4162\n",
      "recall_10                all     0.5779\n",
      "MRR@10: 0.3656724447982087\n",
      "gamma1: 0.6, gamma2: 0.3, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 147.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4244\n",
      "recall_10                all     0.5857\n",
      "MRR@10: 0.37400816462902003\n",
      "gamma1: 0.6, gamma2: 0.2, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 145.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4278\n",
      "recall_10                all     0.5903\n",
      "MRR@10: 0.37698465341739534\n",
      "gamma1: 0.6, gamma2: 0.1, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 148.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4277\n",
      "recall_10                all     0.5892\n",
      "MRR@10: 0.37718740041637516\n",
      "gamma1: 0.6, gamma2: 0.0, gamma3: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 146.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4215\n",
      "recall_10                all     0.5833\n",
      "MRR@10: 0.37103279889828167\n",
      "gamma1: 0.5, gamma2: 0.5, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 148.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3905\n",
      "recall_10                all     0.5542\n",
      "MRR@10: 0.33943388770266136\n",
      "gamma1: 0.5, gamma2: 0.4, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 147.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4019\n",
      "recall_10                all     0.5633\n",
      "MRR@10: 0.35154522202147703\n",
      "gamma1: 0.5, gamma2: 0.3, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:16<00:00, 147.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4094\n",
      "recall_10                all     0.5727\n",
      "MRR@10: 0.3585382562564855\n",
      "gamma1: 0.5, gamma2: 0.2, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:17<00:00, 146.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4102\n",
      "recall_10                all     0.5749\n",
      "MRR@10: 0.3589200607574196\n",
      "gamma1: 0.5, gamma2: 0.1, gamma3: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:14<00:00, 151.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4056\n",
      "recall_10                all     0.5689\n",
      "MRR@10: 0.3546505465781149\n",
      "gamma1: 0.5, gamma2: 0.0, gamma3: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 154.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3974\n",
      "recall_10                all     0.5598\n",
      "MRR@10: 0.3467069142447236\n",
      "gamma1: 0.4, gamma2: 0.6, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 154.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3561\n",
      "recall_10                all     0.5214\n",
      "MRR@10: 0.3046289979097099\n",
      "gamma1: 0.4, gamma2: 0.5, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 153.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3707\n",
      "recall_10                all     0.5344\n",
      "MRR@10: 0.3197230329294556\n",
      "gamma1: 0.4, gamma2: 0.4, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:12<00:00, 156.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3795\n",
      "recall_10                all     0.5438\n",
      "MRR@10: 0.32828568059398683\n",
      "gamma1: 0.4, gamma2: 0.3, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:11<00:00, 157.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3825\n",
      "recall_10                all     0.5478\n",
      "MRR@10: 0.33096333076434015\n",
      "gamma1: 0.4, gamma2: 0.2, gamma3: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 153.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3830\n",
      "recall_10                all     0.5482\n",
      "MRR@10: 0.3316224954059936\n",
      "gamma1: 0.4, gamma2: 0.1, gamma3: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 153.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3756\n",
      "recall_10                all     0.5404\n",
      "MRR@10: 0.32425127151181987\n",
      "gamma1: 0.4, gamma2: 0.0, gamma3: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 154.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3649\n",
      "recall_10                all     0.5307\n",
      "MRR@10: 0.3133668074700192\n",
      "gamma1: 0.3, gamma2: 0.7, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:13<00:00, 153.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3169\n",
      "recall_10                all     0.4815\n",
      "MRR@10: 0.2658230398081821\n",
      "gamma1: 0.3, gamma2: 0.6, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:14<00:00, 151.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3313\n",
      "recall_10                all     0.4982\n",
      "MRR@10: 0.27945994263983126\n",
      "gamma1: 0.3, gamma2: 0.5, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [01:15<00:00, 150.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3417\n",
      "recall_10                all     0.5071\n",
      "MRR@10: 0.29037199178483447\n",
      "gamma1: 0.3, gamma2: 0.4, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 873/11307 [00:06<01:09, 149.57it/s]"
     ]
    }
   ],
   "source": [
    "# PlotQA 2x2 + 4x4\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings_2x2 = np.load('embeddings/PlotQA_corpus_embeddings_2x2.npy')\n",
    "local_image_embeddings_4x4 = np.load('embeddings/PlotQA_corpus_embeddings_4x4.npy')\n",
    "image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/PlotQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/PlotQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/PlotQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-PlotQA/qrels/plotqa-eval-qrels.tsv')\n",
    "\n",
    "# gamma_list = [round(0.1 * i, 1) for i in range(6, 11)]\n",
    "for i in range(11):\n",
    "    for j in range(11 - i):\n",
    "        k = 10 - i - j\n",
    "        gamma_list.append((round(i * 0.1, 1), round(j * 0.1, 1), round(k * 0.1, 1)))\n",
    "gamma_list.reverse()\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor_2x2 = torch.tensor(local_image_embeddings_2x2).cuda()\n",
    "local_image_embeddings_tensor_4x4 = torch.tensor(local_image_embeddings_4x4).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "for gamma1, gamma2, gamma3 in gamma_list:\n",
    "    print(f'gamma1: {gamma1}, gamma2: {gamma2}, gamma3: {gamma3}')\n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores1 = torch.einsum('ijk,k->ij', local_image_embeddings_tensor_2x2, query)\n",
    "        scores2 = torch.einsum('ijk,k->ij', local_image_embeddings_tensor_4x4, query)\n",
    "        \n",
    "        temperature1 = 100.0\n",
    "        temperature2 = 10.0\n",
    "        scaled_scores1 = scores1 * temperature1\n",
    "        scaled_scores2 = scores2 * temperature2\n",
    "        alpha1 = torch.softmax(scaled_scores1, dim=1)\n",
    "        alpha2 = torch.softmax(scaled_scores2, dim=1)\n",
    "        \n",
    "        local_agg1 = torch.einsum('ij,ijk->ik', alpha1, local_image_embeddings_tensor_2x2)\n",
    "        local_agg2 = torch.einsum('ij,ijk->ik', alpha2, local_image_embeddings_tensor_4x4)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma1 * image_embeddings_tensor + gamma2 * local_agg1 + gamma3 * local_agg2\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:12<00:00, 135.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9146\n",
      "recall_10                all     0.9736\n",
      "MRR@10: 0.916935491676345\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:12<00:00, 135.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9227\n",
      "recall_10                all     0.9724\n",
      "MRR@10: 0.9278639179248934\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:12<00:00, 136.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9243\n",
      "recall_10                all     0.9741\n",
      "MRR@10: 0.92918481416957\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:12<00:00, 136.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9200\n",
      "recall_10                all     0.9738\n",
      "MRR@10: 0.9227731804103754\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:11<00:00, 136.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9146\n",
      "recall_10                all     0.9686\n",
      "MRR@10: 0.9176260646535037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SlideVQA\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/SlideVQA_corpus_embeddings_8x8.npy')\n",
    "image_embeddings = np.load('embeddings/SlideVQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/SlideVQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/SlideVQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/SlideVQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-SlideVQA/qrels/slidevqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(6, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 100.0\n",
    "        scaled_scores = scores * temperature\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:02<00:00, 778.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9171\n",
      "recall_10                all     0.9760\n",
      "MRR@10: 0.9190875435540065\n",
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:01<00:00, 838.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9244\n",
      "recall_10                all     0.9766\n",
      "MRR@10: 0.9286147406116917\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:01<00:00, 845.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9259\n",
      "recall_10                all     0.9751\n",
      "MRR@10: 0.9311099012775842\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:01<00:00, 837.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9243\n",
      "recall_10                all     0.9753\n",
      "MRR@10: 0.9286536972512581\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:01<00:00, 845.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9210\n",
      "recall_10                all     0.9735\n",
      "MRR@10: 0.9243304781262098\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1640/1640 [00:01<00:00, 839.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.9146\n",
      "recall_10                all     0.9686\n",
      "MRR@10: 0.9176260646535037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SlideVQA\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/SlideVQA_corpus_embeddings_4x4.npy')\n",
    "image_embeddings = np.load('embeddings/SlideVQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/SlideVQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/SlideVQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/SlideVQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-SlideVQA/qrels/slidevqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 25.0\n",
    "        scaled_scores = scores * temperature\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:28<00:00, 403.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4311\n",
      "recall_10                all     0.5944\n",
      "MRR@10: 0.37998507737165294\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:27<00:00, 405.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4486\n",
      "recall_10                all     0.6088\n",
      "MRR@10: 0.3985223369144835\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:27<00:00, 405.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4524\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.40187680478871707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PlotQA\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings_4x1_with_summary_above.npy')\n",
    "image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/PlotQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/PlotQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/PlotQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-PlotQA/qrels/plotqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(8, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 100.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5\n",
      "image: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 375.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3381\n",
      "recall_10                all     0.4937\n",
      "MRR@10: 0.2899112222938183\n",
      "gamma: 0.5\n",
      "image: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 372.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3642\n",
      "recall_10                all     0.5241\n",
      "MRR@10: 0.3145209597650573\n",
      "gamma: 0.5\n",
      "image: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:29<00:00, 382.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3814\n",
      "recall_10                all     0.5404\n",
      "MRR@10: 0.3318644792311569\n",
      "gamma: 0.5\n",
      "image: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:29<00:00, 381.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3903\n",
      "recall_10                all     0.5505\n",
      "MRR@10: 0.3403400197377397\n",
      "gamma: 0.5\n",
      "image: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:29<00:00, 382.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3918\n",
      "recall_10                all     0.5524\n",
      "MRR@10: 0.3416628061560426\n",
      "gamma: 0.5\n",
      "image: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:29<00:00, 382.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3905\n",
      "recall_10                all     0.5542\n",
      "MRR@10: 0.33943388770266136\n",
      "gamma: 0.6\n",
      "image: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:29<00:00, 380.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3561\n",
      "recall_10                all     0.5163\n",
      "MRR@10: 0.30647105810279174\n",
      "gamma: 0.6\n",
      "image: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 373.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3856\n",
      "recall_10                all     0.5468\n",
      "MRR@10: 0.33540912989705834\n",
      "gamma: 0.6\n",
      "image: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 370.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4041\n",
      "recall_10                all     0.5641\n",
      "MRR@10: 0.3542161689415616\n",
      "gamma: 0.6\n",
      "image: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 368.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4131\n",
      "recall_10                all     0.5731\n",
      "MRR@10: 0.3631684474149332\n",
      "gamma: 0.6\n",
      "image: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 364.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4166\n",
      "recall_10                all     0.5776\n",
      "MRR@10: 0.3663406991876097\n",
      "gamma: 0.6\n",
      "image: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 363.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4162\n",
      "recall_10                all     0.5779\n",
      "MRR@10: 0.3656724447982087\n",
      "gamma: 0.7\n",
      "image: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 367.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3721\n",
      "recall_10                all     0.5319\n",
      "MRR@10: 0.32251604217643076\n",
      "gamma: 0.7\n",
      "image: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 368.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4027\n",
      "recall_10                all     0.5651\n",
      "MRR@10: 0.3520872728089512\n",
      "gamma: 0.7\n",
      "image: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 369.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4214\n",
      "recall_10                all     0.5813\n",
      "MRR@10: 0.37148953240091637\n",
      "gamma: 0.7\n",
      "image: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 371.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4318\n",
      "recall_10                all     0.5929\n",
      "MRR@10: 0.3815416352561488\n",
      "gamma: 0.7\n",
      "image: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 372.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4351\n",
      "recall_10                all     0.5971\n",
      "MRR@10: 0.3844656912911102\n",
      "gamma: 0.7\n",
      "image: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 375.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4341\n",
      "recall_10                all     0.5973\n",
      "MRR@10: 0.38306025484985484\n",
      "gamma: 0.8\n",
      "image: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 360.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3844\n",
      "recall_10                all     0.5465\n",
      "MRR@10: 0.3340261195129874\n",
      "gamma: 0.8\n",
      "image: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 357.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4148\n",
      "recall_10                all     0.5764\n",
      "MRR@10: 0.36428044995304354\n",
      "gamma: 0.8\n",
      "image: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 365.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4336\n",
      "recall_10                all     0.5939\n",
      "MRR@10: 0.3834087185771993\n",
      "gamma: 0.8\n",
      "image: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 368.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4434\n",
      "recall_10                all     0.6044\n",
      "MRR@10: 0.3931422240191151\n",
      "gamma: 0.8\n",
      "image: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 364.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4469\n",
      "recall_10                all     0.6102\n",
      "MRR@10: 0.395898839179551\n",
      "gamma: 0.8\n",
      "image: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 363.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4467\n",
      "recall_10                all     0.6094\n",
      "MRR@10: 0.3958235241267886\n",
      "gamma: 0.9\n",
      "image: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 366.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3949\n",
      "recall_10                all     0.5574\n",
      "MRR@10: 0.3442398724768071\n",
      "gamma: 0.9\n",
      "image: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 367.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4235\n",
      "recall_10                all     0.5849\n",
      "MRR@10: 0.372984322115393\n",
      "gamma: 0.9\n",
      "image: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 370.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4402\n",
      "recall_10                all     0.6002\n",
      "MRR@10: 0.3900829799211336\n",
      "gamma: 0.9\n",
      "image: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 374.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4491\n",
      "recall_10                all     0.6099\n",
      "MRR@10: 0.39875112481241454\n",
      "gamma: 0.9\n",
      "image: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 370.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4515\n",
      "recall_10                all     0.6135\n",
      "MRR@10: 0.40074711409282937\n",
      "gamma: 0.9\n",
      "image: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 371.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4518\n",
      "recall_10                all     0.6143\n",
      "MRR@10: 0.40101657773454097\n",
      "gamma: 1.0\n",
      "image: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 359.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4018\n",
      "recall_10                all     0.5637\n",
      "MRR@10: 0.35133401699467187\n",
      "gamma: 1.0\n",
      "image: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 359.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4277\n",
      "recall_10                all     0.5892\n",
      "MRR@10: 0.37715528798707443\n",
      "gamma: 1.0\n",
      "image: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 369.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4420\n",
      "recall_10                all     0.6024\n",
      "MRR@10: 0.39179420389953734\n",
      "gamma: 1.0\n",
      "image: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:30<00:00, 366.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4497\n",
      "recall_10                all     0.6094\n",
      "MRR@10: 0.3996904572388784\n",
      "gamma: 1.0\n",
      "image: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 363.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4530\n",
      "recall_10                all     0.6138\n",
      "MRR@10: 0.4027080078220969\n",
      "gamma: 1.0\n",
      "image: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:31<00:00, 363.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4524\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.40187680478871707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# PlotQA 使用混合分数\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings_2x2.npy')\n",
    "image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/PlotQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/PlotQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/PlotQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-PlotQA/qrels/plotqa-eval-qrels.tsv')\n",
    "\n",
    "keyword_embeddings = np.load('embeddings/PlotQA_keyword_embeddings.npy')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "gamma_list_2 = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "\n",
    "# gamma_list = [0.9]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "keyword_embeddings_tensor = torch.tensor(keyword_embeddings, dtype=torch.float32).cuda()\n",
    "keyword_embeddings_tensor = torch.squeeze(keyword_embeddings_tensor, 1)\n",
    "# print(keyword_embeddings_tensor.shape)\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    \n",
    "    for gamma_2 in gamma_list_2:\n",
    "        print(f'gamma: {gamma}') \n",
    "        print(f'image: {gamma_2}')\n",
    "        run = {} \n",
    "        for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "            qid = query_ids[q_idx]\n",
    "            \n",
    "            scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "            \n",
    "            temperature = 100.0\n",
    "            scaled_scores = scores * temperature\n",
    "            # scaled_scores = scores / d_k\n",
    "            alpha = torch.softmax(scaled_scores, dim=1)\n",
    "            local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "            \n",
    "\n",
    "            final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "            final_score = torch.matmul(final_fusion, query)\n",
    "            # print(final_fusion.shape)\n",
    "            # print('final score', final_score)\n",
    "            \n",
    "            keyword_score = torch.matmul(keyword_embeddings_tensor, query)\n",
    "            # print(keyword_embeddings_tensor.shape)\n",
    "            # print('keyword score', keyword_score)\n",
    "            \n",
    "            final_scores = gamma_2 * final_score + (1 - gamma_2) * keyword_score\n",
    "            \n",
    "            top_k_indices = torch.argsort(final_scores, descending=True)[:10]  # 取前10个\n",
    "            run[qid] = {corpus_ids[idx]: float(final_scores[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "        for cutoff in [10]:    \n",
    "            evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "            eval_results = evaluator.evaluate(run)  \n",
    "            \n",
    "            for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "                value = pytrec_eval.compute_aggregated_measure(  \n",
    "                    measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "                )  \n",
    "                print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "            \n",
    "            mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "            print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma1: 1.0, gamma2: 0.0, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 327.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4524\n",
      "recall_10                all     0.6140\n",
      "MRR@10: 0.40187680478871707\n",
      "gamma1: 0.9, gamma2: 0.1, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 330.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4518\n",
      "recall_10                all     0.6143\n",
      "MRR@10: 0.40101657773454097\n",
      "gamma1: 0.9, gamma2: 0.0, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 330.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4474\n",
      "recall_10                all     0.6109\n",
      "MRR@10: 0.3961653547949654\n",
      "gamma1: 0.8, gamma2: 0.2, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 330.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4467\n",
      "recall_10                all     0.6094\n",
      "MRR@10: 0.3958235241267886\n",
      "gamma1: 0.8, gamma2: 0.1, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 329.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4457\n",
      "recall_10                all     0.6102\n",
      "MRR@10: 0.39415251964999903\n",
      "gamma1: 0.8, gamma2: 0.0, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 324.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4330\n",
      "recall_10                all     0.5986\n",
      "MRR@10: 0.3812878242302508\n",
      "gamma1: 0.7, gamma2: 0.3, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 325.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4341\n",
      "recall_10                all     0.5973\n",
      "MRR@10: 0.38306025484985484\n",
      "gamma1: 0.7, gamma2: 0.2, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 329.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4393\n",
      "recall_10                all     0.6044\n",
      "MRR@10: 0.38775312666265255\n",
      "gamma1: 0.7, gamma2: 0.1, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 326.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4288\n",
      "recall_10                all     0.5957\n",
      "MRR@10: 0.3766225726162054\n",
      "gamma1: 0.7, gamma2: 0.0, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 327.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3902\n",
      "recall_10                all     0.5627\n",
      "MRR@10: 0.33650372504179954\n",
      "gamma1: 0.6, gamma2: 0.4, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 328.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4162\n",
      "recall_10                all     0.5779\n",
      "MRR@10: 0.3656724447982087\n",
      "gamma1: 0.6, gamma2: 0.3, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 331.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4235\n",
      "recall_10                all     0.5882\n",
      "MRR@10: 0.3720072268758934\n",
      "gamma1: 0.6, gamma2: 0.2, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 331.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4168\n",
      "recall_10                all     0.5842\n",
      "MRR@10: 0.3645533178632158\n",
      "gamma1: 0.6, gamma2: 0.1, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:33<00:00, 333.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3805\n",
      "recall_10                all     0.5534\n",
      "MRR@10: 0.3266743736497007\n",
      "gamma1: 0.6, gamma2: 0.0, gamma3: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 332.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3058\n",
      "recall_10                all     0.4757\n",
      "MRR@10: 0.25324391688811954\n",
      "gamma1: 0.5, gamma2: 0.5, gamma3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 329.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3905\n",
      "recall_10                all     0.5542\n",
      "MRR@10: 0.33943388770266136\n",
      "gamma1: 0.5, gamma2: 0.4, gamma3: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 325.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.4007\n",
      "recall_10                all     0.5655\n",
      "MRR@10: 0.349293666937606\n",
      "gamma1: 0.5, gamma2: 0.3, gamma3: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 331.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3954\n",
      "recall_10                all     0.5647\n",
      "MRR@10: 0.34269184281123893\n",
      "gamma1: 0.5, gamma2: 0.2, gamma3: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11307/11307 [00:34<00:00, 327.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.3617\n",
      "recall_10                all     0.5365\n",
      "MRR@10: 0.3073668720458333\n",
      "gamma1: 0.5, gamma2: 0.1, gamma3: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 11030/11307 [00:34<00:00, 329.23it/s]"
     ]
    }
   ],
   "source": [
    "# PlotQA 使用混合编码\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings_2x2.npy')\n",
    "image_embeddings = np.load('embeddings/PlotQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/PlotQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/PlotQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/PlotQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-PlotQA/qrels/plotqa-eval-qrels.tsv')\n",
    "\n",
    "keyword_embeddings = np.load('embeddings/PlotQA_keyword_embeddings_with_instruction.npy')\n",
    "\n",
    "# gamma_list = [round(0.1 * i, 1) for i in range(8, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "gamma_list = []\n",
    "\n",
    "for i in range(11):\n",
    "    for j in range(11 - i):\n",
    "        k = 10 - i - j\n",
    "        gamma_list.append((round(i * 0.1, 1), round(j * 0.1, 1), round(k * 0.1, 1)))\n",
    "gamma_list.reverse()\n",
    "\n",
    "# print(len(gamma_list)) \n",
    "# print(gamma_list)\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "keyword_embeddings_tensor = torch.tensor(keyword_embeddings, dtype=torch.float32).cuda()\n",
    "keyword_embeddings_tensor = torch.squeeze(keyword_embeddings_tensor, 1)\n",
    "# print(keyword_embeddings_tensor.shape)\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma1, gamma2, gamma3 in gamma_list:\n",
    "    print(f'gamma1: {gamma1}, gamma2: {gamma2}, gamma3: {gamma3}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 100.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        # final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        \n",
    "        final_fusion = gamma1 * image_embeddings_tensor + gamma2 * local_agg + gamma3 * keyword_embeddings_tensor\n",
    "        \n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [01:53<00:00, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7055\n",
      "recall_10                all     0.8096\n",
      "MRR@10: 0.6723660714285689\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [01:53<00:00, 76.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7151\n",
      "recall_10                all     0.8149\n",
      "MRR@10: 0.6833274544385634\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [01:55<00:00, 75.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7164\n",
      "recall_10                all     0.8148\n",
      "MRR@10: 0.6851061875367406\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [02:07<00:00, 67.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7114\n",
      "recall_10                all     0.8115\n",
      "MRR@10: 0.6796276087595516\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [02:59<00:00, 48.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7000\n",
      "recall_10                all     0.8042\n",
      "MRR@10: 0.66699133781599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ArxivQA\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/ArxivQA_corpus_embeddings_4x4.npy')\n",
    "image_embeddings = np.load('embeddings/ArxivQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/ArxivQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/ArxivQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/ArxivQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-ArxivQA/qrels/arxivqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(6, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 20.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:39<00:00, 220.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7298\n",
      "recall_10                all     0.8346\n",
      "MRR@10: 0.6964588385508497\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:39<00:00, 216.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7424\n",
      "recall_10                all     0.8440\n",
      "MRR@10: 0.7100931896678389\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:38<00:00, 223.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7470\n",
      "recall_10                all     0.8488\n",
      "MRR@10: 0.7146937922545535\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:39<00:00, 220.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7444\n",
      "recall_10                all     0.8462\n",
      "MRR@10: 0.712152180702526\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:39<00:00, 218.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.7342\n",
      "recall_10                all     0.8381\n",
      "MRR@10: 0.7012619415049944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ArxivQA in domain\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/ArxivQA_corpus_embeddings_4x4_in_domain.npy')\n",
    "image_embeddings = np.load('embeddings/ArxivQA_corpus_embeddings_in_domain.npy').squeeze(1)\n",
    "query_embeddings = np.load('embeddings/ArxivQA_query_embeddings_in_domain.npy').squeeze(1)\n",
    "corpus_ids = np.load('embeddings/ArxivQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/ArxivQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-ArxivQA/qrels/arxivqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(6, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 20.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [00:02<00:00, 876.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8884\n",
      "recall_10                all     0.9761\n",
      "MRR@10: 0.8600166410650273\n",
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [00:02<00:00, 919.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8901\n",
      "recall_10                all     0.9775\n",
      "MRR@10: 0.8617734565315203\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [00:02<00:00, 913.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8906\n",
      "recall_10                all     0.9736\n",
      "MRR@10: 0.8635772083352723\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [00:02<00:00, 878.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8877\n",
      "recall_10                all     0.9721\n",
      "MRR@10: 0.8603033018355594\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [00:02<00:00, 863.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8805\n",
      "recall_10                all     0.9663\n",
      "MRR@10: 0.8524637698024786\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [00:02<00:00, 866.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8711\n",
      "recall_10                all     0.9624\n",
      "MRR@10: 0.8412190258964445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# InfoVQA\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/InfoVQA_corpus_embeddings_4x4.npy')\n",
    "image_embeddings = np.load('embeddings/InfoVQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/InfoVQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/InfoVQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/InfoVQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-InfoVQA/qrels/infographicsvqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 100.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 719.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6126\n",
      "recall_10                all     0.7312\n",
      "MRR@10: 0.5754929919971701\n",
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 747.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6189\n",
      "recall_10                all     0.7298\n",
      "MRR@10: 0.5837179997347127\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 726.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6271\n",
      "recall_10                all     0.7409\n",
      "MRR@10: 0.5912239686961132\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 747.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6317\n",
      "recall_10                all     0.7409\n",
      "MRR@10: 0.5971144493080425\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 718.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6305\n",
      "recall_10                all     0.7382\n",
      "MRR@10: 0.5964943405403011\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:01<00:00, 715.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6204\n",
      "recall_10                all     0.7242\n",
      "MRR@10: 0.5873922270858202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ChartQA\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/ChartQA_corpus_embeddings_4x4.npy')\n",
    "image_embeddings = np.load('embeddings/ChartQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/ChartQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/ChartQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/ChartQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-ChartQA/qrels/chartqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 25.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 789.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6299\n",
      "recall_10                all     0.7521\n",
      "MRR@10: 0.5912449705973382\n",
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 1053.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6355\n",
      "recall_10                all     0.7618\n",
      "MRR@10: 0.5955873900163591\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 1206.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6355\n",
      "recall_10                all     0.7563\n",
      "MRR@10: 0.5974466109563604\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 1436.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6326\n",
      "recall_10                all     0.7577\n",
      "MRR@10: 0.593229097581465\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 1467.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6225\n",
      "recall_10                all     0.7409\n",
      "MRR@10: 0.5848609453066275\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [00:00<00:00, 1467.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.6131\n",
      "recall_10                all     0.7298\n",
      "MRR@10: 0.5761296812132461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ChartQA in domain\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/ChartQA_corpus_embeddings_4x4_in_domain.npy')\n",
    "image_embeddings = np.load('embeddings/ChartQA_corpus_embeddings_in_domain.npy').squeeze(1)\n",
    "query_embeddings = np.load('embeddings/ChartQA_query_embeddings_in_domain.npy').squeeze(1)\n",
    "corpus_ids = np.load('embeddings/ChartQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/ChartQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-ChartQA/qrels/chartqa-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 100.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [00:02<00:00, 813.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8422\n",
      "recall_10                all     0.9553\n",
      "MRR@10: 0.8058864897741955\n",
      "gamma: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [00:02<00:00, 816.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8452\n",
      "recall_10                all     0.9558\n",
      "MRR@10: 0.8098454513968082\n",
      "gamma: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [00:02<00:00, 818.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8410\n",
      "recall_10                all     0.9516\n",
      "MRR@10: 0.8055971599212681\n",
      "gamma: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [00:02<00:00, 799.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8372\n",
      "recall_10                all     0.9462\n",
      "MRR@10: 0.8021665948621773\n",
      "gamma: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [00:02<00:00, 816.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8311\n",
      "recall_10                all     0.9404\n",
      "MRR@10: 0.7963662704748387\n",
      "gamma: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1879/1879 [00:02<00:00, 827.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_cut_10              all     0.8133\n",
      "recall_10                all     0.9292\n",
      "MRR@10: 0.7764369345396483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MP-DocVQA\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        print(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    "\n",
    "\n",
    "local_image_embeddings = np.load('embeddings/MP_DocVQA_corpus_embeddings_4x4.npy')\n",
    "image_embeddings = np.load('embeddings/MP_DocVQA_corpus_embeddings.npy')\n",
    "query_embeddings = np.load('embeddings/MP_DocVQA_queries_with_instruction_embeddings.npy')\n",
    "corpus_ids = np.load('embeddings/MP_DocVQA_corpus_corpus_ids.npy')\n",
    "query_ids = np.load('embeddings/MP_DocVQA_queries_query_ids.npy')\n",
    "qrels = load_beir_qrels('dataset/VisRAG-Ret-Test-MP-DocVQA/qrels/docvqa_mp-eval-qrels.tsv')\n",
    "\n",
    "gamma_list = [round(0.1 * i, 1) for i in range(5, 11)]\n",
    "# gamma_list = [round(0.80 + 0.01 * i, 2) for i in range(21)]\n",
    "\n",
    "# 将numpy数组转换为PyTorch张量并移动到GPU\n",
    "local_image_embeddings_tensor = torch.tensor(local_image_embeddings).cuda()\n",
    "image_embeddings_tensor = torch.tensor(image_embeddings).cuda()\n",
    "query_embeddings_tensor = torch.tensor(query_embeddings).cuda()\n",
    "\n",
    "# embedding_dim = local_image_embeddings_tensor.size(-1)\n",
    "# d_k = math.sqrt(embedding_dim)\n",
    "# batch_size = local_image_embeddings_tensor.size(0)\n",
    "# d_k = math.sqrt(batch_size)\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    print(f'gamma: {gamma}') \n",
    "    run = {} \n",
    "    for q_idx, query in enumerate(tqdm(query_embeddings_tensor)):\n",
    "        qid = query_ids[q_idx]\n",
    "        \n",
    "        scores = torch.einsum('ijk,k->ij', local_image_embeddings_tensor, query)\n",
    "        \n",
    "        temperature = 35.0\n",
    "        scaled_scores = scores * temperature\n",
    "        # scaled_scores = scores / d_k\n",
    "        alpha = torch.softmax(scaled_scores, dim=1)\n",
    "        local_agg = torch.einsum('ij,ijk->ik', alpha, local_image_embeddings_tensor)\n",
    "        \n",
    "\n",
    "        final_fusion = gamma * image_embeddings_tensor + (1 - gamma) * local_agg\n",
    "        final_score = torch.matmul(final_fusion, query)\n",
    "        \n",
    "        top_k_indices = torch.argsort(final_score, descending=True)[:10]  # 取前10个\n",
    "        run[qid] = {corpus_ids[idx]: float(final_score[idx].cpu().numpy()) for idx in top_k_indices}\n",
    "    for cutoff in [10]:    \n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"ndcg_cut.{cutoff}\", f\"recall.{cutoff}\"})  \n",
    "        eval_results = evaluator.evaluate(run)  \n",
    "        \n",
    "        for measure in sorted(eval_results[next(iter(eval_results))].keys()):  \n",
    "            value = pytrec_eval.compute_aggregated_measure(  \n",
    "                measure, [query_measures[measure] for query_measures in eval_results.values()]  \n",
    "            )  \n",
    "            print(f\"{measure:25s}{'all':8s}{value:.4f}\")  \n",
    "\n",
    "        \n",
    "        mrr = eval_mrr(qrels, run, cutoff)['all']  \n",
    "        print(f'MRR@{cutoff}: {mrr}')  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

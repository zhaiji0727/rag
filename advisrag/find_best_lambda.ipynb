{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'encoded_PlotQA_image_keywords.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m embeded_queries \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings/PlotQA_queries_with_instruction_embeddings.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m embeded_info_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoded_PlotQA_image_keywords.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m embeded_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings/PlotQA_corpus_embeddings.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m image_id \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings/PlotQA_corpus_corpus_ids.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\.conda\\envs\\LLM\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'encoded_PlotQA_image_keywords.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "embeded_queries = np.load('embeddings/PlotQA_queries_with_instruction_embeddings.npy')\n",
    "embeded_info_json = json.load(open('encoded_PlotQA_image_keywords.json', 'r'))\n",
    "embeded_image = np.load('embeddings/PlotQA_corpus_embeddings.npy')\n",
    "image_id = np.load('embeddings/PlotQA_corpus_corpus_ids.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/30/2024 13:53:56 - INFO - __main__ -   Evaluating PlotQA dataset\n",
      "Weight Iteration: 100%|██████████| 10/10 [10:38<00:00, 63.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import csv  \n",
    "import pytrec_eval  \n",
    "import logging  \n",
    "import numpy as np  \n",
    "import json\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "  \n",
    "logging.basicConfig(  \n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",  \n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",  \n",
    "    level=logging.INFO  \n",
    ")  \n",
    "logger = logging.getLogger(__name__)  \n",
    "  \n",
    "def eval_mrr(qrel, run, cutoff=None):  \n",
    "    \"\"\"  \n",
    "    Compute MRR@cutoff manually.  \n",
    "    \"\"\"  \n",
    "    mrr = 0.0  \n",
    "    num_ranked_q = 0  \n",
    "    results = {}  \n",
    "    for qid in qrel:  \n",
    "        if qid not in run:  \n",
    "            continue  \n",
    "        num_ranked_q += 1  \n",
    "        docid_and_score = [(docid, score) for docid, score in run[qid].items()]  \n",
    "        docid_and_score.sort(key=lambda x: x[1], reverse=True)  \n",
    "        for i, (docid, _) in enumerate(docid_and_score):  \n",
    "            rr = 0.0  \n",
    "            if cutoff is None or i < cutoff:  \n",
    "                if docid in qrel[qid] and qrel[qid][docid] > 0:  \n",
    "                    rr = 1.0 / (i + 1)  \n",
    "                    break  \n",
    "        results[qid] = rr  \n",
    "        mrr += rr  \n",
    "    mrr /= num_ranked_q  \n",
    "    results[\"all\"] = mrr  \n",
    "    return results  \n",
    "\n",
    "def retrieve_and_evaluate(query_embeddings, query_ids, corpus_embeddings, keyword_embeddings, corpus_ids, qrels):  \n",
    "    try: \n",
    "        query_embeddings = torch.tensor(query_embeddings)\n",
    "        corpus_embeddings = torch.tensor(corpus_embeddings)\n",
    "        keyword_embeddings = torch.tensor(keyword_embeddings)\n",
    "        # 定义cutoff数组\n",
    "        cutoffs = [10]\n",
    "        \n",
    "        # 打开CSV文件以写入结果\n",
    "        with open('PlotQA_evaluation_results.csv', mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # 写入表头\n",
    "            header = ['image_weight', 'keyword_weight']\n",
    "            for cutoff in cutoffs:\n",
    "                header.append(f'ndcg@{cutoff}')\n",
    "            for cutoff in cutoffs:\n",
    "                header.append(f'recall@{cutoff}')\n",
    "            for cutoff in cutoffs:\n",
    "                header.append(f'mrr@{cutoff}')\n",
    "            writer.writerow(header)\n",
    "            \n",
    "            for weight_i in tqdm(np.arange(0, 1.0, 0.1), desc=\"Weight Iteration\", leave=True):\n",
    "                weight_k = 1 - weight_i\n",
    "                weight_i = round(weight_i, 2)\n",
    "                weight_k = round(weight_k, 2)\n",
    "                # weight_matrix = np.array([[weight_i, weight_k]])\n",
    "                weight_matrix = torch.tensor([[weight_i, weight_k]], dtype=torch.float32)\n",
    "                run = {}  \n",
    "\n",
    "                for q_idx, q_emb in enumerate(query_embeddings):  \n",
    "                    qid = query_ids[q_idx]  \n",
    "                    # scores_i = np.dot(corpus_embeddings, q_emb)  \n",
    "                    # scores_k = np.dot(keyword_embeddings, q_emb)\n",
    "                    # scores_k = np.array([item[0] for item in scores_k])\n",
    "\n",
    "                    # scores_matrix = np.array([scores_i, scores_k])\n",
    "                    # scores = np.dot(weight_matrix, scores_matrix)\n",
    "                    \n",
    "                    # top_k_indices = np.argsort(scores.flatten())[::-1][:10]  # 取前10个  \n",
    "\n",
    "                    # run[qid] = {corpus_ids[idx]: float(scores.flatten()[idx]) for idx in top_k_indices}  \n",
    "                    \n",
    "                    scores_i = torch.matmul(corpus_embeddings, q_emb)\n",
    "                    scores_k = torch.matmul(keyword_embeddings, q_emb)\n",
    "                    scores_k = scores_k.squeeze()\n",
    "\n",
    "                    scores_matrix = torch.stack([scores_i, scores_k])\n",
    "                    scores = torch.matmul(weight_matrix, scores_matrix)\n",
    "\n",
    "                    top_k_indices = torch.argsort(scores.flatten(), descending=True)[:10]\n",
    "\n",
    "                    run[qid] = {corpus_ids[idx]: float(scores.flatten()[idx]) for idx in top_k_indices}\n",
    "\n",
    "                # 评估\n",
    "                row = [weight_i, weight_k]\n",
    "                evaluator = pytrec_eval.RelevanceEvaluator(qrels, {\"ndcg_cut\", \"recall\"}) \n",
    "                \n",
    "                eval_results = evaluator.evaluate(run)\n",
    "                \n",
    "                for cutoff in cutoffs:\n",
    "                    ndcg_measure = f\"ndcg_cut_{cutoff}\"\n",
    "                    \n",
    "                    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {ndcg_measure}) \n",
    "                    eval_results = evaluator.evaluate(run)\n",
    "                    \n",
    "                    # recall_measure = f\"recall_{cutoff}\"\n",
    "                    \n",
    "                    ndcg_value = pytrec_eval.compute_aggregated_measure(\n",
    "                        ndcg_measure, [query_measures[ndcg_measure] for query_measures in eval_results.values()]\n",
    "                    )\n",
    "                    \n",
    "                    # recall_value = pytrec_eval.compute_aggregated_measure(\n",
    "                    #     recall_measure, [query_measures[recall_measure] for query_measures in eval_results.values()]\n",
    "                    # )\n",
    "                    \n",
    "                    row.append(ndcg_value)\n",
    "                \n",
    "                for cutoff in cutoffs:\n",
    "                    recall_measure = f\"recall_{cutoff}\"\n",
    "                    \n",
    "                    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {recall_measure}) \n",
    "                    eval_results = evaluator.evaluate(run)\n",
    "                \n",
    "                    recall_value = pytrec_eval.compute_aggregated_measure(\n",
    "                        recall_measure, [query_measures[recall_measure] for query_measures in eval_results.values()]\n",
    "                    )\n",
    "                    # recall_value = pytrec_eval.compute_aggregated_measure(\n",
    "                    #     f\"recall_{cutoff}\", [query_measures[f\"recall_{cutoff}\"] for query_measures in eval_results.values()]\n",
    "                    # )\n",
    "                    row.append(recall_value)\n",
    "                \n",
    "                for cutoff in cutoffs:\n",
    "                    mrr_value = eval_mrr(qrels, run, cutoff)['all']\n",
    "                    row.append(mrr_value)\n",
    "                \n",
    "                writer.writerow(row)\n",
    "\n",
    "    except Exception as e:  \n",
    "        logger.error(f\"Error during retrieval and evaluation: {e}\") \n",
    "  \n",
    "def load_beir_qrels(qrels_file):  \n",
    "    qrels = {}  \n",
    "    try:  \n",
    "        with open(qrels_file) as f:  \n",
    "            tsvreader = csv.DictReader(f, delimiter=\"\\t\")  \n",
    "            for row in tsvreader:  \n",
    "                qid = row[\"query-id\"]  \n",
    "                pid = row[\"corpus-id\"]  \n",
    "                rel = int(row[\"score\"])  \n",
    "                if qid in qrels:  \n",
    "                    qrels[qid][pid] = rel  \n",
    "                else:  \n",
    "                    qrels[qid] = {pid: rel}  \n",
    "    except Exception as e:  \n",
    "        logger.error(f\"Error loading qrels file: {e}\")  \n",
    "    return qrels \n",
    " \n",
    "def load_embeddings_and_ids(embeddings_path, ids_path):\n",
    "    embeddings = np.load(embeddings_path)\n",
    "    ids = np.load(ids_path).astype(str)\n",
    "    return embeddings, ids\n",
    "\n",
    "datasets = [\n",
    "    # {\n",
    "    #     \"name\": \"SlideVQA\",\n",
    "    #     \"query_embeddings_path\": \"embeddings/SlideVQA_queries_with_instruction_embeddings.npy\",\n",
    "    #     \"query_ids_path\": \"embeddings/SlideVQA_queries_query_ids.npy\",\n",
    "    #     \"corpus_embeddings_path\": \"embeddings/SlideVQA_corpus_embeddings.npy\",\n",
    "    #     \"corpus_ids_path\": \"embeddings/SlideVQA_corpus_corpus_ids.npy\",\n",
    "    #     \"qrels_path\": \"dataset/VisRAG-Ret-Test-SlideVQA/qrels/slidevqa-eval-qrels.tsv\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"MP_DocVQA\",\n",
    "    #     \"query_embeddings_path\": \"embeddings/MP_DocVQA_queries_with_instruction_embeddings.npy\",\n",
    "    #     \"query_ids_path\": \"embeddings/MP_DocVQA_queries_query_ids.npy\",\n",
    "    #     \"corpus_embeddings_path\": \"embeddings/MP_DocVQA_corpus_embeddings.npy\",\n",
    "    #     \"corpus_ids_path\": \"embeddings/MP_DocVQA_corpus_corpus_ids.npy\",\n",
    "    #     \"qrels_path\": \"dataset/VisRAG-Ret-Test-MP-DocVQA/qrels/docvqa_mp-eval-qrels.tsv\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"ArxivQA\",\n",
    "    #     \"query_embeddings_path\": \"embeddings/ArxivQA_queries_with_instruction_embeddings.npy\",\n",
    "    #     \"query_ids_path\": \"embeddings/ArxivQA_queries_query_ids.npy\",\n",
    "    #     \"corpus_embeddings_path\": \"embeddings/ArxivQA_corpus_embeddings.npy\",\n",
    "    #     \"corpus_ids_path\": \"embeddings/ArxivQA_corpus_corpus_ids.npy\",\n",
    "    #     \"qrels_path\": \"dataset/VisRAG-Ret-Test-ArxivQA/qrels/arxivqa-eval-qrels.tsv\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"ChartQA\",\n",
    "    #     \"query_embeddings_path\": \"embeddings/ChartQA_queries_with_instruction_embeddings.npy\",\n",
    "    #     \"query_ids_path\": \"embeddings/ChartQA_queries_query_ids.npy\",\n",
    "    #     \"corpus_embeddings_path\": \"embeddings/ChartQA_corpus_summary_embeddings.npy\",\n",
    "    #     \"corpus_ids_path\": \"embeddings/ChartQA_corpus_corpus_ids.npy\",\n",
    "    #     \"qrels_path\": \"dataset/VisRAG-Ret-Test-ChartQA/qrels/chartqa-eval-qrels.tsv\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"InfoVQA\",\n",
    "    #     \"query_embeddings_path\": \"embeddings/InfoVQA_queries_with_instruction_embeddings.npy\",\n",
    "    #     \"query_ids_path\": \"embeddings/InfoVQA_queries_query_ids.npy\",\n",
    "    #     \"corpus_embeddings_path\": \"embeddings/InfoVQA_corpus_embeddings.npy\",\n",
    "    #     \"corpus_ids_path\": \"embeddings/InfoVQA_corpus_corpus_ids.npy\",\n",
    "    #     \"qrels_path\": \"dataset/VisRAG-Ret-Test-InfoVQA/qrels/infographicsvqa-eval-qrels.tsv\"\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"PlotQA\",\n",
    "        \"query_embeddings_path\": \"embeddings/PlotQA_queries_with_instruction_embeddings.npy\",\n",
    "        \"query_ids_path\": \"embeddings/PlotQA_queries_query_ids.npy\",\n",
    "        \"corpus_embeddings_path\": \"embeddings/PlotQA_corpus_embeddings.npy\",\n",
    "        \"corpus_ids_path\": \"embeddings/PlotQA_corpus_corpus_ids.npy\",\n",
    "        \"qrels_path\": \"dataset/VisRAG-Ret-Test-PlotQA/qrels/plotqa-eval-qrels.tsv\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 循环评估每个数据集\n",
    "for dataset in datasets:\n",
    "    logger.info(f\"Evaluating {dataset['name']} dataset\")\n",
    "    query_embeddings, query_ids = load_embeddings_and_ids(dataset[\"query_embeddings_path\"], dataset[\"query_ids_path\"])\n",
    "    corpus_embeddings, corpus_ids = load_embeddings_and_ids(dataset[\"corpus_embeddings_path\"], dataset[\"corpus_ids_path\"])\n",
    "    \n",
    "    # embeded_info_json = json.load(open('encoded_PlotQA_image_keywords.json', 'r'))\n",
    "    # INSTRUCTION = 'Represent these key words extracted from image: '\n",
    "    # keyword_embeddings_list = []\n",
    "    # keyword_embeddings_list = [embeded_info_json[id]['keywords_vector'] for id in tqdm(list(corpus_ids))]\n",
    "    # keyword_embeddings = np.array(keyword_embeddings_list)\n",
    "    # np.save('embeddings/PlotQA_keyword_embeddings_with_instruction.npy', keyword_embeddings)\n",
    "    \n",
    "    keyword_embeddings = np.load('embeddings/PlotQA_keyword_embeddings_with_instruction.npy')\n",
    "    \n",
    "    \n",
    "    qrels = load_beir_qrels(dataset[\"qrels_path\"])\n",
    "    retrieve_and_evaluate(query_embeddings, query_ids, corpus_embeddings, keyword_embeddings, corpus_ids, qrels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
